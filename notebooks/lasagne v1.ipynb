{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from holidays import US\n",
    "us_holidays = US()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lasagne.layers import DenseLayer, InputLayer, DropoutLayer\n",
    "from lasagne.nonlinearities import softmax\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet, TrainSplit\n",
    "from theano.tensor import TensorType, vector\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv.gz', parse_dates=True, nrows=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/test.csv.gz', parse_dates=True, nrows=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "street_encoder = LabelEncoder()\n",
    "\n",
    "def get_street_name(addr):\n",
    "    sp = addr.split(' ')\n",
    "    if sp[0].isdigit():\n",
    "        return ' '.join(sp[1:])\n",
    "    return addr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streets = pd.concat([train['Address'].apply(get_street_name), test['Address'].apply(get_street_name)])\n",
    "street_encoder.fit(streets.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seasons = dict(zip([1,2,3,4,5,6,7,8,9,10,11,12], ['Winter','Winter','Spring','Spring','Spring','Summer','Summer','Summer','Autumn','Autumn','Autumn','Winter']))\n",
    "def get_season(d):\n",
    "    return seasons[d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "def get_dates(d):\n",
    "    dt = datetime.strptime(d, '%Y-%m-%d %H:%M:%S')\n",
    "    season = get_season(dt.month)\n",
    "    # http://www.timeanddate.com/sun/usa/san-francisco\n",
    "    if season == 'Winter':\n",
    "        isDaytime = int(6 < dt.hour < 18)\n",
    "    elif season == 'Summer':\n",
    "        isDaytime = int(5 < dt.hour < 21)\n",
    "    else:\n",
    "        isDaytime = int(6 < dt.hour < 19)\n",
    "    is_holiday = dt in us_holidays\n",
    "    return dt.hour, dt.month, dt.year, season, isDaytime, is_holiday\n",
    "\n",
    "def get_features(data):\n",
    "    df = pd.DataFrame()\n",
    "    df['Hour'], df['Month'], df['Year'], seasons, df['IsDaytime'], df['IsHoliday'] = zip(*data['Dates'].apply(get_dates))\n",
    "    df['isWeekend'] = data['DayOfWeek'].apply(lambda x: int(x == 'Saturday' or x == 'Sunday'))\n",
    "    df = df.join(pd.get_dummies(data['PdDistrict'], prefix='District'))\n",
    "    df = df.join(pd.get_dummies(data['DayOfWeek'], prefix='Day'))\n",
    "    df = df.join(pd.get_dummies(seasons, prefix='Season'))\n",
    "    xy_fitted = StandardScaler().fit_transform(data[['X', 'Y']])\n",
    "    df['X'] = xy_fitted[:, 0]\n",
    "    df['Y'] = xy_fitted[:, 1]\n",
    "    df['IsIntersection'] = data['Address'].map(lambda x: int('/' in x))\n",
    "    df['Street'] = street_encoder.transform(data['Address'].apply(get_street_name))\n",
    "    labels = None\n",
    "    if 'Category' in data:\n",
    "        labels = label_encoder.fit_transform(data['Category'])\n",
    "    return df, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features, labels = get_features(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(features)\n",
    "features_scaled = scaler.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, labels, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_classes = len(label_encoder.classes_)\n",
    "num_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net0 = NeuralNet(layers=[\n",
    "                    ('input', InputLayer),\n",
    "                    ('dense0', DenseLayer),\n",
    "                    ('dropout', DropoutLayer),\n",
    "                    ('dense1', DenseLayer),\n",
    "                    ('output', DenseLayer)],\n",
    "\n",
    "                 input_shape=(None, num_features),\n",
    "                 dense0_num_units=200,\n",
    "                 dropout_p=0.5,\n",
    "                 dense1_num_units=200,\n",
    "                 output_num_units=num_classes,\n",
    "                 output_nonlinearity=softmax,\n",
    "                 update=nesterov_momentum,\n",
    "                 update_learning_rate=0.01,\n",
    "                 update_momentum=0.9,\n",
    "                 \n",
    "                 train_split=TrainSplit(eval_size=0.2),\n",
    "                 verbose=1,\n",
    "                 max_epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(X_tensor_type=None,\n",
       "     batch_iterator_test=<nolearn.lasagne.base.BatchIterator object at 0x7f613745ec90>,\n",
       "     batch_iterator_train=<nolearn.lasagne.base.BatchIterator object at 0x7f613745ec10>,\n",
       "     custom_score=None, dense0_num_units=200, dense1_num_units=200,\n",
       "     dropout_p=0.5, input_shape=(None, 31),\n",
       "     layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('dense0', <class 'lasagne.layers.dense.DenseLayer'>), ('dropout', <class 'lasagne.layers.noise.DropoutLayer'>), ('dense1', <class 'lasagne.layers.dense.DenseLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],\n",
       "     loss=None, max_epochs=20, more_params={},\n",
       "     objective=<function objective at 0x7f613746b2a8>,\n",
       "     objective_loss_function=<function categorical_crossentropy at 0x7f61386e7938>,\n",
       "     on_epoch_finished=[<nolearn.lasagne.handlers.PrintLog instance at 0x7f61301be758>],\n",
       "     on_training_finished=[],\n",
       "     on_training_started=[<nolearn.lasagne.handlers.PrintLayerInfo instance at 0x7f61307b6710>],\n",
       "     output_nonlinearity=<function softmax at 0x7f6138880758>,\n",
       "     output_num_units=39, regression=False,\n",
       "     train_split=<nolearn.lasagne.base.TrainSplit object at 0x7f612f7a5390>,\n",
       "     update=<function nesterov_momentum at 0x7f61386f10c8>,\n",
       "     update_learning_rate=0.01, update_momentum=0.9,\n",
       "     use_label_encoder=False, verbose=1,\n",
       "     y_tensor_type=TensorType(int32, vector))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started 2015-10-01 14:28:01.920301\n",
      "# Neural Network with 54439 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input        31\n",
      "  1  dense0      200\n",
      "  2  dropout     200\n",
      "  3  dense1      200\n",
      "  4  output       39\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  ------\n",
      "      1       \u001b[36m2.58333\u001b[0m       \u001b[32m2.52922\u001b[0m      1.02140      0.24258  16.52s\n",
      "      2       \u001b[36m2.53051\u001b[0m       \u001b[32m2.51843\u001b[0m      1.00480      0.24699  24.92s\n",
      "      3       \u001b[36m2.51881\u001b[0m       \u001b[32m2.51210\u001b[0m      1.00267      0.24699  27.59s\n"
     ]
    }
   ],
   "source": [
    "print 'started', datetime.now()\n",
    "res = net0.fit(features_scaled, labels.astype('int32'))\n",
    "print 'finished', datetime.now()\n",
    "print res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(net0, open('lasagne_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.281416666667\n"
     ]
    }
   ],
   "source": [
    "print 'score', net0.score(features_scaled, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " logloss 2.39604583542\n"
     ]
    }
   ],
   "source": [
    "print 'logloss', log_loss(labels, net0.predict_proba(features_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_features, _ = get_features(test)\n",
    "\n",
    "scaler.fit(test_features)\n",
    "test_features = scaler.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proba = model.predict_proba(test_features)\n",
    "prediction = pd.DataFrame(proba, columns=label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with gzip.GzipFile('lrv2.csv.gz', mode='w', compresslevel=9) as f:\n",
    "    prediction.to_csv(f, index_label=\"Id\", na_rep=\"0\", float_format='%11.5f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
