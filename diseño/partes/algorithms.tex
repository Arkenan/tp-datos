
\section{Algoritmos de predicción} % (fold)
\label{sec:algoritmos_de_prediccion}

\subsection{Regresión Logística} % (fold)
\label{sub:regresion_logistica}

La regresión logística a pesar de su nombre es un algoritmo de clasificación, el cual puede implementarse para realizar una clasificación binaria, o una clasificación de múltiples valores posibles.

El modelo de la regresión logística es análogo al de la regresión lineal, dado que tal como la misma, parte de una función hipótesis que se le aplica a los datos de entrada.
\begin{equation}
h_{\theta}(x)= \Theta^T \cdot x
\end{equation}
\begin{small}
Esta es la representación vectorial de la función hipótesis de la regresión lineal. Donde $X$ es el vector traspuesto de datos $x_{i}$, y $\Theta^T$ es el vector de pesos $\theta_{j}$.
\end{small} \newline

En el caso de la regresión lineal, el valor de retorno de la función hipótesis puede variar mucho dependiendo del vector de datos de entrada $X$ y el vector de pesos $\Theta$. En este aspecto la regresión logística se diferencia de la regresión lineal.

\subsubsection{Función sigmoidal.}
En el caso particular de la regresión logística, la función hipótesis se construye de la siguiente manera:
\begin{equation}
h_{\theta}(x)= \frac{1}{1+e^{- \Theta^T\cdot x }}
\end{equation}

Similarmente, la hipótesis de la regresión logística utiliza el vector de datos de entrada $X$ y el de pesos $\Theta$, y su función retorna un valor escalar. Sin embargo, esta nueva función otorga una ventaja al retornar un número escalar real comprendido entre 1 y 0. Este tipo de función se llama función sigmoidal, y el valor escalar comprendido entre 1 y 0 se puede interpretar como una probabilidad.
\begin{figure}[H]
\centering
\includegraphics[width=80mm]{logisticCurve}
\caption{Gráfica de una función sigmoidal.}
\label{fig:logisticCurve}
\end{figure}

\subsubsection{Uno contra todos.}
Sin embargo, hasta el momento el algoritmo parece ser sólo diseñado para resolver problemas de clasificación binaria. Para utilizar este algoritmo de forma pueda abordar un problema de salida multiclase, debe aplicarse algún esquema de clasificación que aproveche las salidas binarias (o de probabilidad entre 0 y 1) de la función sigmoidal. Para eso se utiliza el esquema \textit{ovr (One-vs-rest)}. One-vs-rest no aplica otra cosa que el criterio de \textit{dividir y conquistar}. Por cada clase se resuelve el problema en forma binaria, donde el caso positivo (1) corresponde a la clase misma, y el caso negativo corresponde a cualquier otra clase. A continuación puede verse una representación gráfica de esta estrategia:

\begin{figure}[H]
\centering
\includegraphics[width=80mm]{oneVsRest}
\caption{Representación gráfica one-vs-rest. \cite{AndrewNgMulticlass}}
\label{fig:oneVsRest}
\end{figure}

\subsubsection{Estimación y Función de Costo.}
De esta manera se cuenta con una serie de funciones $h_{\theta}^k(x)$ donde $k$ es el número de la clase que representa la función. A través del valor de retorno de todas estas funciones se obtiene entonces la probabilidad de cada clase distinta para cada caso del set de valores de entrada.

Este conjunto de probabilidades obtenido, es una estimación, y esa estimación debe aproximarse al valor deseado. En este trabajo disponemos de un set de entrenamiento asociado a las clasificaciones correctas. El objetivo de la regresión logística es esbozar una función de costo dados los pesos $\theta_{j}$ . De esta manera, optimizando (o minimizando) la función costo se pueden corregir los pesos $\theta_{j}$, de forma que las estimaciones posteriores se asemejen cada vez más a los valores deseados o ``correctos''.

A continuación se muestra un ejemplo ilustrativo de una definición de función de costo:

\begin{equation}
J(h_{\theta }(x),y) = \begin{cases}
- \log h_{\theta}(x) & \textit{si $y \equiv 1$} \\
- \log (1- h_{\theta}(x)) & \textit{si $y \equiv 0$}
\end{cases}
\end{equation}

La conveniencia de esta función de costo es que:

\begin{itemize}
  \item Cuando el valor esperado es $1$, y la estimación se aproxima a $0$, el costo tiende a $\infty$.
  \item Cuando el valor esperado es $1$, y la estimación se aproxima a $1$, el costo tiende a $0$.
  \item Cuando el valor esperado es $0$, y la estimación se aproxima a $1$, el costo tiende a $\infty$.
  \item Cuando el valor esperado es $0$, y la estimación se aproxima a $0$, el costo tiende a $0$.
\end{itemize}

Esto ocurre gracias a que las funciones logarítmicas de cada caso se comportan como describen las siguientes gráficas:

\begin{figure}[H]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.8\linewidth]{minusLogX}
  \caption{$y = - \log (x)$}
  \label{fig:minusLogX}
\end{subfigure}%
\begin{subfigure}{.34\textwidth}
  \centering
  \includegraphics[width=.8\linewidth]{minusLog1minusX}
  \caption{$y = - \log (1-x)$}
  \label{fig:minusLog1minusX}
\end{subfigure}
\caption{Gráficas}
\label{fig:minusLog}
\end{figure}

Análogamente, se pueden definir funciones de costo de forma contínua, obteniendo comportamientos similares. En el caso particular de la clase LogisticRegression implementada en el paquete de python \textit{sklearn}, una función de costo utilizada es la siguiente:

\begin{equation}
J(\theta,c)= \Theta^T \cdot \Theta + C \sum_{i=1}^n \log (e^{-y_{i} \cdot (X_{i}^T \Theta + c)})
\end{equation}
Donde:

\begin{itemize}
  \item $X_{i}$ es el vector de parámetros de entrada del i-ésimo caso de un set de entrenamiento.
  \item $y_{i}$ es el valor correcto conocido del i-ésimo caso de un set de entrenamiento.
  \item $c$ es una constante de ajuste, al igual que los pesos comprendidos en el vector $\Theta$.
  \item $\Theta^T \cdot \Theta$ y $C$ son complementos de la función de costo pensados para regularizarla, suavizando su comportamiento con el fin de evitar cometer \textit{overfitting}.
\end{itemize}

\subsubsection{Optimización: descenso por el gradiente.}
Por último, queda detallar el método de optimización utilizado por la regresión logística. Los métodos de optimización de la función de costo pueden ser derivativos o no derivativos.

El método derivativo clásico es el descenso por el gradiente. El descenso por el gradiente consiste en calcular el gradiente de la función costo. De esta forma se obtiene la dirección y sentido de máximo crecimiento de la función. Con el fin de minimizarla, lo que se hace es, a través de un escalar que se denomina \textit{paso} de la optimización, se van variando los valores de $\theta_{i}$ en la misma dirección y sentido opuesto que el gradiente, de forma de apuntar hacia la minimización de la función de costo. Esto se realiza iterativamente, recalculando el gradiente de la función costo con los parámetros $\theta_{i}$ actualizados.

Sin embargo, las librería \textit{sklearn} utiliza en el modo \textit{liblinear} un método no derivativo denominado \textit{descenso coordenado} \cite{sklearnLinearModel}. El descenso coordenado consiste en partir la optimización en optimizaciones más simples, de una variable. Esto lo hace minimizando la función de costo por una coordenada o variable a la vez. Itera por cada variable y calcula la dirección de descenso de la función modificando el valor de esa sola variable.

A continuación se muestra una gráfica que ilustra este método de optimización:

\begin{figure}[H]
\centering
\includegraphics[width=80mm]{coordinateDescent}
\caption{Descenso coordenado. Las elipses concéntricas son curvas de nivel, donde el centro de las elipses se encuentra un mínimo local. \cite{wikipediaCoordinateDescent}}
\label{fig:coordinateDescent}
\end{figure}



\input{./partes/redes.tex}
