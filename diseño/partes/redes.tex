\subsection{Redes Neuronales}
Las redes neuronales son estructuras de predicción de propósito general, que se basan en unidades, llamadas \emph{neuronas}. Particularmente en este caso, vamos a usar una red neuronal para clasificación, y veremos como influye eso a la hora de construirla.

Históricamente %Buscar referencia!
surgieron de un acercamiento al aprendizaje automático que seguía como heurística conseguir un parecido entre la inteligencia artificial y el funcionamiento de la mente humana. Una red tiene capas de neuronas, cada una de las cuales obtiene con input una combinación lineal de los datos de la capa anterior. Cada neurona, a ese input, le aplica una \emph{función de activación}, que será su output.

Para el caso de una sola neurona de clasificación, podemos comparar el comportamiento con el de una regresión logística:

\begin{figure}[h]
\centering
\def\svgwidth{0.25\columnwidth}
\caption{Neurona clasificadora}
\input{./images/neurona.pdf_tex}
\end{figure}

En la figura se ve una capa $l$ (de "layer") con tres neuronas. Cada una tiene como output su función de activación $a$. La neurona de la capa siguiente toma como input una combinación lineal de las anteriores y le aplica su propia función de activación, la función sigmoidea.
\begin{eqnarray}
 h_{\theta} = g(z)  \\
 z = \sum_{i = 1}^{3}\theta_i a_i^{(l)}=\theta^T a^{(l)}
\end{eqnarray}
De esta forma obtenemos la ya vista regresión logística.

Una red neuronal es más general. Tiene una capa inicial, con los datos de entrada para la predicción, una capa de salida, con la hipótesis, y una cantidad arbitraria de capas llamadas \emph{ocultas} entre ellas. Estas últimas permiten que la hipótesis final sirva para modelar problemas muy complejos, ya que las activaciones de cada capa anterior actúan como nuevas features para las capas siguientes:

\begin{figure}[h]
\centering
\def\svgwidth{0.25\columnwidth}
\caption{Red Neuronal}
\input{./images/red.pdf_tex}
\end{figure}

La red presentada en la figura, por ejemplo, tiene 3 capas. La de las features del ejemplo (input), una capa oculta (capa 2) y una capa de output, que es la que da como resultado la hipótesis. La necesidad de múltiples hipótesis corresponde a que la clasificación de crímenes es multiclase. Cada neurona del output dará como resultado la probabilidad de pertenencia del ejemplo a cada clase.

\subsubsection{FeedForward}
El paso hacia adelante (obtención de la hipótesis según features) se hace repitiendo el esquema de la neurona única. La diferencia radica principalmente en que ahora en lugar de tener un vector $\theta$, como de las salidas de un una capa de neuronas obtenemos las entradas de la siguiente (de un vector obtenemos otro), necesitaremos en cada paso una matriz que llamaremos $\Theta^{(l)}$.

Las capas se relacionan de la siguiente manera:
\begin{eqnarray}
\text{Activación: } \qquad a^{(l)} = g(z(l)) \\
\text{Combinacion lineal: } \qquad z^{(l+1)} = \Theta^{(l)} a^{(l)}
\end{eqnarray}
Y particularmente para la red de arriba se cumple que
\begin{eqnarray}
a^{(1)} = x \\
a^{(3)} = h_{\Theta}
\end{eqnarray}
\subsubsection{Función de costo} Como es un problema de clasificación, al igual que en un problema de regresión logística, se usa una función de costo logarítmica, pero se suma el costo para la probabilidad asignada a cada clase.

\begin{equation}
J(\Theta) = -{1}/{m} \left[ \sum_{i = 1}^{m}\sum_{k = 1}^{K} y_k^{(i)}log(h_\Theta(x^{(i)})_k) + (1-y_k^{(i)})(1-log(h_\Theta(x^{(i)})_k)) \right]
\end{equation}
siendo $m$ la cantidad de ejemplos y $K$ la cantidad de clases.

Una observación importante es que el costo se puede obtener como un promedio de los costos individuales de cada ejemplo:
\begin{equation}
J(\Theta) = 1/m \sum_{i=1}^{m}J(\Theta)^{(i)}
\end{equation}

Una segunda observación es que basta conocer la salida de la última capa para poder obtener el costo de la predicción. Estas dos serán asunciones que tendremos que hacer más adelante para el algoritmo de \emph{Backpropagation}.

\subsubsection{Backpropagation} Como se desea hacer descenso por el gradiente para minimizar el costo, es necesario computar el gradiente de la función de costo según los parámetros $\Theta_{ij}^{(l)}$. Sin embargo, calcular manualmente las derivadas de la hipótesis en cuanto a los parámetros de todas las matrices se vuelve complicado por la cantidad de pasos intermedios que hay entre la primera y la última capa. Además, si así se calculara sería poco generalizable ya que dependería de la estructura de la red y de la cantidad de capas ocultas.

Para solucionar este problema surgió en los 70\cite{chap2} un algoritmo llamado \emph{backpropagation}, que permite calcular las derivadas parciales en función capa a capa, partiendo de los resultados. Recordando la primera observación sobre la función de costo, trabajaremos solo con el costo individual para un ejemplo, y para simplificar la notación, lo llamaremos simplemente $J$.

Para comenzar, definimos provisionalmente un error de cada neurona como el cambio del costo en función de su entrada:
\begin{equation}
\delta_i^{(l)} = \frac{\partial J}{\partial z_i^{(l)}}
\end{equation}

Particularizamos este error en la última capa $(L)$:
\begin{equation}
\delta_i^{(L)} = \frac{\partial J}{\partial z_i^{(L)}} = \frac{\partial J}{\partial h_{\Theta_i}}\frac{dh_{\Theta_i}}{dz_i^{(L)}} = \frac{\partial J}{\partial h_{\Theta_i}}g'(z_i^{(L)})
\end{equation}

Para el caso particular de la activación sigmoidea y del costo logarítmico:
\begin{equation}
\delta_i^{L} = h_{\Theta_i} - y_{i}
\end{equation}

O directamente en forma vectorial:
\begin{equation} \label{eq:errorFinal}
\delta^{L} = h_{\Theta} - y
\end{equation}

Teniendo este error, lo que backpropagation propone (como su nombre lo indica) es propagar el error hacia atrás, obteniendo el error de la capa $l$ en función del de la capa $l+1$. Llamo $J_l$ al costo en función de los inputs $z$ de la capa $l$ (o sea, $J(z_1^{(l)}, ... , z_{n_l}^{(l)})$), y $J_{l+1}$ al costo en función de los costos de la capa l+1(o sea, $J(z_1^{(l+1)}, ... , z_{n_{l+1}}^{(l+1)})$). De esta forma, podemos decir:
\begin{equation}
J_l(z^{(l)}) = J_{l+1}(\Theta^{(l)} g(z^{(l)})) 
\end{equation}
y aplicando la regla de la cadena en forma vectorial:
\begin{equation}
\nabla J_l(z^{(l)})^T = \nabla J_{l+1}(\Theta^{(l)} g(z^{(l)}))^T D(\Theta^{(l)} g(z^{(l)}))
\end{equation}
Los gradientes $J_l$ y $J_l+1$ son las derivadas de la función de costo respecto a $z^{(l)}$ y $z^{(l+1)}$, que son justamente los errores $\delta$ de aquellas capas. La matriz diferencial de la derecha se calcula fácilmente y la ecuación anterior queda:
\begin{equation}
\delta^{(l)^T} = \delta^{(l+1)^T} \Theta^{(l)} \odot g'(z^{(l)})^T
\end{equation}
Donde $\odot$ es el producto elemento a elemento entre vectores, o ``Producto de Hadamard''. Trasponiendo:
\begin{equation}
\delta^{(l)} = \Theta^{(l)^T} \delta^{(l+1)} \odot g'(z^{(l)})
\end{equation}
Con lo cual obtuvimos el error en una capa, vectorialmente, dado el error de la capa siguiente. Particularmente, como la función de activación g es la sigmoidea y su derivada es conocida:
\begin{equation}
\delta^{(l)} = \Theta^{(l)^T} \delta^{(l+1)} \odot g(z^{(l)}) \odot (1-g(z^{(l)}))
\end{equation}
\begin{equation} \label{eq:error}
\delta^{(l)} = \Theta^{(l)^T} \delta^{(l+1)} \odot a^{(l)} \odot (1-a^{(l)})
\end{equation}

Ahora, lo único que falta es calcular, teniendo los errores $\delta$ de cada capa, poder calcular las derivadas del costo no según las entradas, sino según los parámetros de cada $\Theta$, que era nuestro objetivo original. De forma análoga a la última resolución, llamamos $J_{\Theta^{(l)}}$ al costo como función de los parámetros de combinación lineal de la capa $l$ a la capa $l+1$ y $J_{z^{(l+1)}}$ al costo como función de las entradas de la capa $l+1$.

\begin{equation}
D J_{\Theta^{(l)}}^T = \nabla J_{z^{(l+1)}}^T D_{\Theta^{(l)}} (\Theta^{(l)} z^{(l)})
\end{equation}

Como lo que nos interesa no es en sí la forma vectorial separada por capas, sino armar un gradiente con todos los parámetros, entonces queda expresado cada componente de la siguiente forma:

\begin{equation} \label{eq:params}
\frac{\partial J}{\partial \Theta_{ij}^{(l)}} = \frac{\partial J}{\partial z_j^{l+1}}g(z_i^{(l)}) = \delta_j^{(l+1)}a_i^{(l)}
\end{equation}

De esta manera pudimos, a través de únicamente lo obtenido en la última capa (hipótesis) generar las derivadas parciales respecto a cada parámetro para un ejemplo en particular.

Resumiendo los pasos:
\begin{description}
\item[FeedForward:] se toma el ejemplo y se obtiene la hipótesis yendo hacia adelante en las capas.
\item[Backpropagation:] se toma la hipótesis obtenida en el paso anterior y se buscan las derivadas según los siguientes pasos:
	\begin{enumerate}
	\item Calcular el error de la última capa como diferencia entre la hipótesis y los datos conocidos (ecuación \ref{eq:errorFinal}).
	\item Propagar los errores hacia atrás con la matriz de parámetros traspuesta y la capa siguiente (ecuación \ref{eq:error}).
	\item Una vez obtenidos los errores calcular a través de ellos las derivadas parciales respecto a los parámetros con la ecuación \ref{eq:params}.
	
	\end{enumerate}
\end{description}

\subsubsection{Bias} Al igual que en la regresión logística se añadía un término independiente a la combinación lineal, en las redes neuronales se añade en cada capa una neurona que tiene siempre activación (salida) 1. Esto no afecta las cuentas hechas atrás. Lo único que cambia es el tamaño de las matrices $\Theta$, que tendrán una columna más para cada capa.

\subsubsection{Regularización} También, como ya veníamos haciendo, para evitar el overfitting, habrá una penalización en el costo para los valores de parámetros muy altos.
El costo con regularización es el siguiente:

\begin{equation}
J(\Theta) = -\frac{1}{m} \left[ \sum_{i = 1}^{m}\sum_{k = 1}^{K} y_k^{(i)}log(h_\Theta(x^{(i)})_k) + (1-y_k^{(i)})(1-log(h_\Theta(x^{(i)})_k)) \right] + \frac{\lambda}{2m}\sum_{l = 1}^{L}\sum_{j=1}^{s_l}\sum_{i=1}^{s_{l+1}}(\Theta_{ij}^{(l)})^2
\end{equation}

Como el término que se agrega está sumado al costo anterior, el backpropagation planteado sirve, en tanto y en cuando se le agregue la derivada del costo por regularización. Algo a destacar es que los índices parten del 1 y no del 0 para i ya que no se regularizan los parámetros de bias. Quedará entonces:

\begin{equation}
\frac{\partial J(\Theta)}{\partial \Theta_{ij}^{(l)}} = \frac{1}{m}\sum_{ej = 1}^{m} \frac{\partial J_{BP}^{(ej)}}{\partial \Theta_{ij}^{(l)}} + \frac{\lambda}{m}\Theta_{ij}^{(l)} \qquad \text{para}\qquad j \neq 0
\end{equation}
\begin{equation}
\frac{\partial J(\Theta)}{\partial \Theta_{ij}^{(l)}} = \frac{1}{m}\sum_{ej = 1}^{m} \frac{\partial J_{BP}^{(ej)}}{\partial \Theta_{ij}^{(l)}} \qquad \text{para}\qquad j = 0
\end{equation}

Siendo $\frac{\partial J_{BP}^{(ej)}}{\partial \Theta_{ij}^{(l)}}$ la derivada parcial individual del costo para el ejemplo $ej$ respecto del parámetro correspondiente utilizando backpropagation.

\

\subsubsection{Método de ajuste}
Para la red en sí, la arquitectura inicial pensada es una capa oculta, con 2 o 3 veces la cantidad de nodos respecto de la capa de input. Después de lograr estabilizar el $\lambda$ de la regularización y el $\alpha$ del descenso por el gradiente, el plan es agregar una o dos capas ocultas más de la misma cantidad de nodos y evaluar el desempeño en el cross validation set (la parte separada del training set para hacer pruebas).

Para asegurarse de que las derivadas están siendo correctamente calculadas por el backpropagation se utilizará gradient-checkin, un método para obtener una aproximación numérica del gradiente para tener algo con qué comparar. Si bien no será una buena aproximación, diferencias muy grandes, como cambios de signo u órdenes de magnitud, indican que errores de implementación del backpropagation.